{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr/>\n",
    "\n",
    "# Introduction to Data Science\n",
    "**Tamás Budavári** - budavari@jhu.edu <br/>\n",
    "\n",
    "- Classification exercises\n",
    "- Cross-validation\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><font color=\"darkblue\">Classification</font></h1>\n",
    "\n",
    "- Based on a **training set** of labeled points, assign class labels to unknown vectors in the **query set**.  \n",
    "\n",
    "> **Training set**\n",
    "><br>\n",
    "><br>\n",
    ">$\\qquad \\displaystyle T = \\big\\{ (x_i, C_i) \\big\\}$ \n",
    "><br>\n",
    "><br>\n",
    "> where $x_i\\in \\mathbb{R}^d$ are feature sets and $C_i$ are the known class memberships\n",
    "\n",
    "<nbsp/>\n",
    "\n",
    "> **Query set**\n",
    "><br>\n",
    "><br>\n",
    ">$\\qquad \\displaystyle Q = \\big\\{ x_i \\big\\}$ \n",
    "><br>\n",
    "><br>\n",
    "> where $x_i\\in \\mathbb{R}^d$ consist of the kind of features in $T$\n",
    "\n",
    "- And again, $x_i$ are not real vectors but **feature sets** of a bunch of scalars in general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes with Covariance Matrix\n",
    "\n",
    "- Estimate the full covariance matrix for the classes\n",
    "\n",
    ">$\\displaystyle {\\cal{}L}_{\\!\\boldsymbol{x}}(C_k) =  G(\\boldsymbol{x};\\mu_k, \\Sigma_k)$\n",
    "><br>\n",
    "> Handles correlated features well\n",
    "\n",
    "- Consider binary problem with 2 classes - using Bayes' rule\n",
    "\n",
    ">$ \\displaystyle \\frac{P(C_1|x)}{P(C_2|x)} = \\frac{\\pi_1}{\\pi_2}\\cdot \\frac{{\\cal{}L}_{\\!\\boldsymbol{x}}(C_1)}{{\\cal{}L}_{\\!\\boldsymbol{x}}(C_2)} $\n",
    "\n",
    "> Taking the negative logarithm, we compare\n",
    "><br><br>\n",
    ">$\\displaystyle (x\\!-\\!\\mu_1)^T\\,\\Sigma_1^{-1}(x\\!-\\!\\mu_1) + \\ln\\,\\lvert\\Sigma_1\\lvert $ \n",
    "> <br> vs.\n",
    "><br>\n",
    ">$\\displaystyle (x\\!-\\!\\mu_2)^T\\,\\Sigma_2^{-1}(x\\!-\\!\\mu_2) + \\ln\\,\\lvert\\Sigma_2\\lvert $\n",
    "><br>\n",
    "><br>\n",
    "> If the difference is higher/lower than a threshold (based on the priors), we classify $x$ accordingly\n",
    "\n",
    "- This is called **Quadratic Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Covariance Matrix\n",
    "\n",
    "- When $\\Sigma_1=\\Sigma_2=\\Sigma$, the quadratic terms cancel from the difference\n",
    " \n",
    ">$\\displaystyle (x\\!-\\!\\mu_1)^T\\,\\Sigma^{-1}(x\\!-\\!\\mu_1) $ \n",
    ">$\\displaystyle -\\ (x\\!-\\!\\mu_2)^T\\,\\Sigma^{-1}(x\\!-\\!\\mu_2) $\n",
    "\n",
    "- Hence this is called **Linear Discriminant Analysis**\n",
    "\n",
    "> Fewer parameters to estimate during the learning process\n",
    "> <br>\n",
    "> Good, if we don't have enough data, for example...\n",
    "> <br>\n",
    "> Think linear vs quadratic fitting and how you decide between those"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: QDA \n",
    "\n",
    "- Use the provided [training](Class-Train.csv) and [query](Class-Query.csv) sets to perform classification\n",
    "\n",
    "> **Training** set consists of 3 columns of ($x_i$, $y_i$, $C_i$)\n",
    "> <br>\n",
    "> **Query** set only has 2 columns of ($x_i$, $y_i$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Best class?\n",
    ">$\\displaystyle \\max_k \\big[\\ P(C_k|x)\\ \\big]$\n",
    ">\n",
    ">$\\displaystyle \\max_k \\big[\\ \\pi_k {\\cal{}L}_{\\!x}(C_k)\\ \\big]$\n",
    ">\n",
    ">$\\displaystyle \\min_k \\big[ -\\ln\\pi_k - \\ln{\\cal{}L}_{\\!x}(C_k)\\ \\big]$\n",
    "\n",
    "> #### Multivariate normal\n",
    ">$\\displaystyle {\\cal{}L}_{\\!x}(C_k) = \\frac{1}{\\sqrt{\\lvert2\\pi\\Sigma_k\\rvert}} \\exp\\left(-\\frac{1}{2} (x\\!-\\!\\mu_k)^T \\Sigma_k^{-1} (x\\!-\\!\\mu_k)\\right)$\n",
    ">\n",
    "> Hence,\n",
    ">\n",
    ">$\\displaystyle \\min_k \\Big[ \\frac{1}{2} (x\\!-\\!\\mu_k)^T \\Sigma_k^{-1} (x\\!-\\!\\mu_k) + \\frac{1}{2}\\ln\\lvert\\Sigma_k\\rvert -\\ln\\pi_k \\ \\Big]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyQDA(object):\n",
    "    \"\"\" Template for classifier\n",
    "    \"\"\"\n",
    "    def fit(self,X,C):\n",
    "        self.param = dict()\n",
    "        # your code here\n",
    "        return self\n",
    "\n",
    "    def predict(self,Y):\n",
    "        Cpred = None\n",
    "        # your code here\n",
    "        # use linalg.det(matrix)\n",
    "        # and linalg.inv(matrix)\n",
    "        return Cpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyQDA(object):\n",
    "    \"\"\" Simple implementation for illustration purposes\n",
    "    \"\"\"       \n",
    "    def fit(self,X,C):\n",
    "        self.param = dict()\n",
    "        for k in np.unique(C):\n",
    "            members = (C==k)\n",
    "            prior = members.sum() / C.size\n",
    "            S = X[members,:] # subset of class \n",
    "            mu = S.mean(axis=0)    \n",
    "            Z = (S-mu).T # centered column vectors\n",
    "            cov = Z @ Z.T / (Z.shape[1] - 1)\n",
    "            self.param[k] = (prior, mu, cov)\n",
    "        return self\n",
    "            \n",
    "    def predict(self,Y):\n",
    "        Cpred = -1 * np.ones(Y.shape[0])\n",
    "        for i in range(Cpred.size):\n",
    "            d2min, kbest = 1e99, None\n",
    "            for k in self.param:\n",
    "                prior, mu, cov = self.param[k]\n",
    "                diff = (Y[i,:]-mu).T\n",
    "                d2 = diff.T @ np.linalg.inv(cov) @ diff / 2\n",
    "                d2 += np.log(np.linalg.det(cov)) / 2 - np.log(prior) \n",
    "                if d2 < d2min: \n",
    "                    d2min,kbest = d2,k\n",
    "            Cpred[i] = kbest\n",
    "        return Cpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "files/Class-Train.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19224/2715878109.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminant_analysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQuadraticDiscriminantAnalysis\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mQDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'files/Class-Train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'files/Class-Query.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1066\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    529\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: files/Class-Train.csv not found."
     ]
    }
   ],
   "source": [
    "# reference implementation\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "D = np.loadtxt('files/Class-Train.csv', delimiter=',')\n",
    "Q = np.loadtxt('files/Class-Query.csv', delimiter=',')\n",
    "X, C = D[:,0:2], D[:,2]\n",
    "\n",
    "Cpred = MyQDA().fit(X,C).predict(Q)\n",
    "Cskit =   QDA().fit(X,C).predict(Q)\n",
    "\n",
    "print ('Number of different estimates:', (Cpred!=Cskit).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><font color=\"darkblue\">Cross-Validation</font></h1>\n",
    "\n",
    "- How to evaluate the quality of estimator?\n",
    "\n",
    "> $k$-NN method's parameter affects the results\n",
    "\n",
    "- We saw on the IRIS data that 1-NN was overfitting\n",
    "\n",
    "> We discussed excluding the point itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions of the Training set\n",
    "\n",
    "- Random complementary subsets \n",
    "\n",
    "> Train on a larger subset, test on a small\n",
    "> <br>\n",
    "> Multiple rounds to decrease variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out\n",
    "\n",
    "- For each point, we train on the others and test\n",
    "\n",
    "> Testing on $n$ points requires $n$ trainings\n",
    "\n",
    "- Expensive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A Relaxed Variant\n",
    "\n",
    "- $k$-fold cross-validation \n",
    "\n",
    "> 1. Create $k$ partitions of equal sizes, e.g., $k=2$ yields two subsets\n",
    "> 2. Pick a single partition and train on the other $(k\\!-\\!1)$ \n",
    "> 3. Repeat for all $k$ partitions - requires $k$ trainings\n",
    "\n",
    "- Leave-One-Out is a special case with $k=n$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Cross-Validation\n",
    "\n",
    "- Evaluate QDA on the [training](files/Class-Train.csv) set using 2-fold cross-validation\n",
    "\n",
    "> 1. What is the fraction of correct estimates? \n",
    "> 2. What is the uncertainty of that fraction?\n",
    " \n",
    "> The **training** set consists of 3 columns of ($x_i$, $y_i$, $C_i$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19224/699409676.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# randomize and split to D1 + D2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'D' is not defined"
     ]
    }
   ],
   "source": [
    "Dc = D.copy()\n",
    "# randomize and split to D1 + D2\n",
    "np.random.seed(seed=42)\n",
    "np.random.shuffle(Dc)\n",
    "split = int(Dc[:,0].size/2)\n",
    "D1, D2 = Dc[:split,:], Dc[split:,:]\n",
    "\n",
    "# train on one, estimate on the other\n",
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case #0 - Number of mislabeled points out of a total 157 points : 19\n",
      "Case #1 - Number of mislabeled points out of a total 156 points : 20\n"
     ]
    }
   ],
   "source": [
    "Dc = D.copy()\n",
    "# randomize and split to D1 + D2\n",
    "np.random.seed(seed=42)\n",
    "np.random.shuffle(Dc)\n",
    "split = Dc.shape[0] // 2\n",
    "D1, D2 = Dc[:split,:], Dc[split:,:]\n",
    "# train on one estimate or the other\n",
    "for i,(T,Q) in enumerate([(D1,D2),(D2,D1)]):\n",
    "    X, C = T[:,0:2], T[:,2]\n",
    "    Cpred, Ctrue = MyQDA().fit(X,C).predict(Q[:,:2]), Q[:,2]\n",
    "    print (\"Case #%d - Number of mislabeled points out of a total %3d points : %2d\" \\\n",
    "        % (i, Q.shape[0],(Ctrue!=Cpred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done already?\n",
    "\n",
    "- Visualize the results in the 2D features space\n",
    "- Make these simple codes run faster \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-fold CV - quick hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19224/1665996937.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# randomize and split to D1 + D2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'D' is not defined"
     ]
    }
   ],
   "source": [
    "Dc = D.copy()\n",
    "print(Dc)\n",
    "# randomize and split to D1 + D2\n",
    "np.random.seed(seed=42)\n",
    "np.random.shuffle(Dc)\n",
    "split = int(Dc[:,0].size/3)\n",
    "split2 = 2*split\n",
    "D1, D2, D3 = Dc[:split,:], Dc[split:split2,:], Dc[split2:]\n",
    "\n",
    "# train on one, estimate on the other\n",
    "for T,Q in [ (np.vstack([D1,D2]),D3), (np.vstack([D2,D3]),D1), (np.vstack([D3,D1]),D2)]:\n",
    "    Cpred = QDA().fit(T[:,:2],T[:,2]).predict(Q[:,:2])\n",
    "    Ctrue = Q[:,2]\n",
    "    print ((Cpred!=Ctrue).sum(), T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unhomework\n",
    "\n",
    "- Implement LDA and compare to sklearn\n",
    "\n",
    ">1. Write code without using sklearn \n",
    ">2. Apply to [training](Class-Train.csv) and [query](Class-Query.csv) sets \n",
    ">3. Compare your results to sklearn's \n",
    "\n",
    "- Perform 10-fold cross-validation of *MyQDA* on [this](Class-Train.csv) file\n",
    "\n",
    ">1. Write code without using `sklearn` \n",
    ">2. Calculate average number of good classifications \n",
    ">3. Compare to sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8125    , 0.875     , 0.75      , 0.875     , 0.8125    ,\n",
       "       0.75      , 1.        , 1.        , 1.        , 0.93333333])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = QDA()\n",
    "cross_val_score(clf, X,C, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\t 0.8125   =   0.8125\n",
      "1 :\t 0.875   =   0.875\n",
      "2 :\t 0.75   =   0.75\n",
      "3 :\t 0.875   =   0.875\n",
      "4 :\t 0.8125   =   0.8125\n",
      "5 :\t 0.75   =   0.75\n",
      "6 :\t 1.0   =   1.0\n",
      "7 :\t 1.0   =   1.0\n",
      "8 :\t 0.9333333333333333   =   0.9333333333333333\n",
      "9 :\t 1.0   =   1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k_fold = KFold(n_splits=10, shuffle=False) \n",
    "\n",
    "for k, (train, test) in enumerate(k_fold.split(X)):\n",
    "    clf.fit(X[train],C[train])\n",
    "    Cpred = clf.predict(X[test])\n",
    "    print (k, ':\\t', (C[test]==Cpred).sum() / float(test.size),\n",
    "        '  =  ', clf.score(X[test],C[test]) )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
