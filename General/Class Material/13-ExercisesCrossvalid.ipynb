{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr/>\n",
    "\n",
    "# Introduction to Data Science\n",
    "**Tamás Budavári** - budavari@jhu.edu <br/>\n",
    "\n",
    "- Classification exercises\n",
    "- Cross-validation\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><font color=\"darkblue\">Classification</font></h1>\n",
    "\n",
    "- Based on a **training set** of labeled points, assign class labels to unknown vectors in the **query set**.  \n",
    "\n",
    "> **Training set**\n",
    "><br>\n",
    "><br>\n",
    ">$\\qquad \\displaystyle T = \\big\\{ (x_i, C_i) \\big\\}$ \n",
    "><br>\n",
    "><br>\n",
    "> where $x_i\\in \\mathbb{R}^d$ are feature sets and $C_i$ are the known class memberships\n",
    "\n",
    "<nbsp/>\n",
    "\n",
    "> **Query set**\n",
    "><br>\n",
    "><br>\n",
    ">$\\qquad \\displaystyle Q = \\big\\{ x_i \\big\\}$ \n",
    "><br>\n",
    "><br>\n",
    "> where $x_i\\in \\mathbb{R}^d$ consist of the kind of features in $T$\n",
    "\n",
    "- And again, $x_i$ are not real vectors but **feature sets** of a bunch of scalars in general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes with Covariance Matrix\n",
    "\n",
    "- Estimate the full covariance matrix for the classes\n",
    "\n",
    ">$\\displaystyle {\\cal{}L}_{\\!\\boldsymbol{x}}(C_k) =  G(\\boldsymbol{x};\\mu_k, \\Sigma_k)$\n",
    "><br>\n",
    "> Handles correlated features well\n",
    "\n",
    "- Consider binary problem with 2 classes - using Bayes' rule\n",
    "\n",
    ">$ \\displaystyle \\frac{P(C_1|x)}{P(C_2|x)} = \\frac{\\pi_1}{\\pi_2}\\cdot \\frac{{\\cal{}L}_{\\!\\boldsymbol{x}}(C_1)}{{\\cal{}L}_{\\!\\boldsymbol{x}}(C_2)} $\n",
    "\n",
    "> Taking the negative logarithm, we compare\n",
    "><br><br>\n",
    ">$\\displaystyle (x\\!-\\!\\mu_1)^T\\,\\Sigma_1^{-1}(x\\!-\\!\\mu_1) + \\ln\\,\\lvert\\Sigma_1\\lvert $ \n",
    "> <br> vs.\n",
    "><br>\n",
    ">$\\displaystyle (x\\!-\\!\\mu_2)^T\\,\\Sigma_2^{-1}(x\\!-\\!\\mu_2) + \\ln\\,\\lvert\\Sigma_2\\lvert $\n",
    "><br>\n",
    "><br>\n",
    "> If the difference is higher/lower than a threshold (based on the priors), we classify $x$ accordingly\n",
    "\n",
    "- This is called **Quadratic Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Covariance Matrix\n",
    "\n",
    "- When $\\Sigma_1=\\Sigma_2=\\Sigma$, the quadratic terms cancel from the difference\n",
    " \n",
    ">$\\displaystyle (x\\!-\\!\\mu_1)^T\\,\\Sigma^{-1}(x\\!-\\!\\mu_1) $ \n",
    ">$\\displaystyle -\\ (x\\!-\\!\\mu_2)^T\\,\\Sigma^{-1}(x\\!-\\!\\mu_2) $\n",
    "\n",
    "- Hence this is called **Linear Discriminant Analysis**\n",
    "\n",
    "> Fewer parameters to estimate during the learning process\n",
    "> <br>\n",
    "> Good, if we don't have enough data, for example...\n",
    "> <br>\n",
    "> Think linear vs quadratic fitting and how you decide between those"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: QDA \n",
    "\n",
    "- Use the provided [training](Class-Train.csv) and [query](Class-Query.csv) sets to perform classification\n",
    "\n",
    "> **Training** set consists of 3 columns of ($x_i$, $y_i$, $C_i$)\n",
    "> <br>\n",
    "> **Query** set only has 2 columns of ($x_i$, $y_i$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Best class?\n",
    ">$\\displaystyle \\max_k \\big[\\ P(C_k|x)\\ \\big]$\n",
    ">\n",
    ">$\\displaystyle \\max_k \\big[\\ \\pi_k {\\cal{}L}_{\\!x}(C_k)\\ \\big]$\n",
    ">\n",
    ">$\\displaystyle \\min_k \\big[ -\\ln\\pi_k - \\ln{\\cal{}L}_{\\!x}(C_k)\\ \\big]$\n",
    "\n",
    "> #### Multivariate normal\n",
    ">$\\displaystyle {\\cal{}L}_{\\!x}(C_k) = \\frac{1}{\\sqrt{\\lvert2\\pi\\Sigma_k\\rvert}} \\exp\\left(-\\frac{1}{2} (x\\!-\\!\\mu_k)^T \\Sigma_k^{-1} (x\\!-\\!\\mu_k)\\right)$\n",
    ">\n",
    "> Hence,\n",
    ">\n",
    ">$\\displaystyle \\min_k \\Big[ \\frac{1}{2} (x\\!-\\!\\mu_k)^T \\Sigma_k^{-1} (x\\!-\\!\\mu_k) + \\frac{1}{2}\\ln\\lvert\\Sigma_k\\rvert -\\ln\\pi_k \\ \\Big]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyQDA(object):\n",
    "    \"\"\" Template for classifier\n",
    "    \"\"\"\n",
    "    def fit(self,X,C):\n",
    "        self.param = dict()\n",
    "        # your code here\n",
    "        return self\n",
    "\n",
    "    def predict(self,Y):\n",
    "        Cpred = None\n",
    "        # your code here\n",
    "        # use linalg.det(matrix)\n",
    "        # and linalg.inv(matrix)\n",
    "        return Cpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyQDA(object):\n",
    "    \"\"\" Simple implementation for illustration purposes\n",
    "    \"\"\"       \n",
    "    def fit(self,X,C):\n",
    "        self.param = dict()\n",
    "        for k in np.unique(C):\n",
    "            members = (C==k)\n",
    "            prior = members.sum() / C.size\n",
    "            S = X[members,:] # subset of class \n",
    "            mu = S.mean(axis=0)    \n",
    "            Z = (S-mu).T # centered column vectors\n",
    "            cov = Z @ Z.T / (Z.shape[1] - 1)\n",
    "            self.param[k] = (prior, mu, cov)\n",
    "        return self\n",
    "            \n",
    "    def predict(self,Y):\n",
    "        Cpred = -1 * np.ones(Y.shape[0])\n",
    "        for i in range(Cpred.size):\n",
    "            d2min, kbest = 1e99, None\n",
    "            for k in self.param:\n",
    "                prior, mu, cov = self.param[k]\n",
    "                diff = (Y[i,:]-mu).T\n",
    "                d2 = diff.T @ np.linalg.inv(cov) @ diff / 2\n",
    "                d2 += np.log(np.linalg.det(cov)) / 2 - np.log(prior) \n",
    "                if d2 < d2min: \n",
    "                    d2min,kbest = d2,k\n",
    "            Cpred[i] = kbest\n",
    "        return Cpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different estimates: 0\n"
     ]
    }
   ],
   "source": [
    "# reference implementation\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "D = np.loadtxt('Class-Train.csv', delimiter=',')\n",
    "Q = np.loadtxt('Class-Query.csv', delimiter=',')\n",
    "X, C = D[:,0:2], D[:,2]\n",
    "\n",
    "Cpred = MyQDA().fit(X,C).predict(Q)\n",
    "Cskit =   QDA().fit(X,C).predict(Q)\n",
    "\n",
    "print ('Number of different estimates:', (Cpred!=Cskit).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><font color=\"darkblue\">Cross-Validation</font></h1>\n",
    "\n",
    "- How to evaluate the quality of estimator?\n",
    "\n",
    "> $k$-NN method's parameter affects the results\n",
    "\n",
    "- We saw on the IRIS data that 1-NN was overfitting\n",
    "\n",
    "> We discussed excluding the point itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions of the Training set\n",
    "\n",
    "- Random complementary subsets \n",
    "\n",
    "> Train on a larger subset, test on a small\n",
    "> <br>\n",
    "> Multiple rounds to decrease variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out\n",
    "\n",
    "- For each point, we train on the others and test\n",
    "\n",
    "> Testing on $n$ points requires $n$ trainings\n",
    "\n",
    "- Expensive!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A Relaxed Variant\n",
    "\n",
    "- $k$-fold cross-validation \n",
    "\n",
    "> 1. Create $k$ partitions of equal sizes, e.g., $k=2$ yields two subsets\n",
    "> 2. Pick a single partition and train on the other $(k\\!-\\!1)$ \n",
    "> 3. Repeat for all $k$ partitions - requires $k$ trainings\n",
    "\n",
    "- Leave-One-Out is a special case with $k=n$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Cross-Validation\n",
    "\n",
    "- Evaluate QDA on the [training](files/Class-Train.csv) set using 2-fold cross-validation\n",
    "\n",
    "> 1. What is the fraction of correct estimates? \n",
    "> 2. What is the uncertainty of that fraction?\n",
    " \n",
    "> The **training** set consists of 3 columns of ($x_i$, $y_i$, $C_i$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dc = D.copy()\n",
    "# randomize and split to D1 + D2\n",
    "np.random.seed(seed=42)\n",
    "np.random.shuffle(Dc)\n",
    "split = int(Dc[:,0].size/2)\n",
    "D1, D2 = Dc[:split,:], Dc[split:,:]\n",
    "\n",
    "# train on one, estimate on the other\n",
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case #0 - Number of mislabeled points out of a total 157 points : 19\n",
      "Case #1 - Number of mislabeled points out of a total 156 points : 20\n"
     ]
    }
   ],
   "source": [
    "Dc = D.copy()\n",
    "# randomize and split to D1 + D2\n",
    "np.random.seed(seed=42)\n",
    "np.random.shuffle(Dc)\n",
    "split = Dc.shape[0] // 2\n",
    "D1, D2 = Dc[:split,:], Dc[split:,:]\n",
    "# train on one estimate or the other\n",
    "for i,(T,Q) in enumerate([(D1,D2),(D2,D1)]):\n",
    "    X, C = T[:,0:2], T[:,2]\n",
    "    Cpred, Ctrue = MyQDA().fit(X,C).predict(Q[:,:2]), Q[:,2]\n",
    "    print (\"Case #%d - Number of mislabeled points out of a total %3d points : %2d\" \\\n",
    "        % (i, Q.shape[0],(Ctrue!=Cpred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done already?\n",
    "\n",
    "- Visualize the results in the 2D features space\n",
    "- Make these simple codes run faster \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-fold CV - quick hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.072856   -12.93877095   0.        ]\n",
      " [ -5.46445715 -12.73849219   0.        ]\n",
      " [-10.88780154 -20.1482205    0.        ]\n",
      " [ -9.03783938 -16.53543305   0.        ]\n",
      " [ -6.22186344 -11.02917434   0.        ]\n",
      " [-11.49811837 -14.01356862   0.        ]\n",
      " [ -6.28537085 -11.03069691   0.        ]\n",
      " [ -6.78279726 -10.7631925    0.        ]\n",
      " [ -8.23295389 -13.99594848   0.        ]\n",
      " [ -6.2276255  -10.50494013   0.        ]\n",
      " [ -7.33747828 -14.86012719   0.        ]\n",
      " [ -4.33245413  -9.53281179   0.        ]\n",
      " [-12.23123917 -18.82298876   0.        ]\n",
      " [ -4.6560809  -13.19907263   0.        ]\n",
      " [ -7.59732258 -13.34147199   0.        ]\n",
      " [ -5.172616   -11.14532048   0.        ]\n",
      " [ -8.05464277 -13.35119947   0.        ]\n",
      " [ -6.72881426 -15.51670133   0.        ]\n",
      " [ -4.82783373 -11.00577341   0.        ]\n",
      " [ -6.77325222 -11.74555133   0.        ]\n",
      " [ -4.811992   -11.00788116   0.        ]\n",
      " [-11.24391376 -21.49968249   0.        ]\n",
      " [ -6.84242298 -13.27265215   0.        ]\n",
      " [-10.61457444 -16.03819023   0.        ]\n",
      " [ -5.50543925 -15.20563976   0.        ]\n",
      " [ -8.03981535 -13.84146148   0.        ]\n",
      " [ -7.80894674 -17.00152197   0.        ]\n",
      " [ -7.1207483  -14.16854006   0.        ]\n",
      " [ -7.01875735 -12.60869455   0.        ]\n",
      " [ -6.9175442  -11.61887025   0.        ]\n",
      " [ -4.89534221 -10.30171231   0.        ]\n",
      " [ -5.3606628  -11.5194511    0.        ]\n",
      " [ -8.65860775 -18.35650756   0.        ]\n",
      " [ -9.18686009 -14.0788143    0.        ]\n",
      " [ -6.44822519 -15.37037983   0.        ]\n",
      " [ -6.77266748 -11.22133293   0.        ]\n",
      " [ -7.18009537  -9.37374323   0.        ]\n",
      " [ -9.14483989 -15.60586519   0.        ]\n",
      " [ -7.82813479 -18.63471812   0.        ]\n",
      " [ -8.52253244 -17.71933994   0.        ]\n",
      " [ -6.04909524  -9.04090889   0.        ]\n",
      " [ -5.49836253 -12.29948196   0.        ]\n",
      " [ -7.98215914 -14.62583374   0.        ]\n",
      " [ -9.7440328  -17.3429484    0.        ]\n",
      " [ -4.91607578 -11.64282878   0.        ]\n",
      " [ -6.35675826 -12.55420458   0.        ]\n",
      " [ -8.45830236 -17.08521994   0.        ]\n",
      " [ -8.81065562 -19.95870712   0.        ]\n",
      " [ -8.12181423 -12.28938642   0.        ]\n",
      " [ -7.84501289 -18.47181552   0.        ]\n",
      " [ -7.26448921 -15.16363264   0.        ]\n",
      " [ -5.47970291 -10.42240248   0.        ]\n",
      " [ -8.93875203 -14.30561048   0.        ]\n",
      " [ -9.05726889 -20.85358428   0.        ]\n",
      " [ -7.78648515 -12.66419286   0.        ]\n",
      " [-10.40522845 -20.31331136   0.        ]\n",
      " [ -9.11588202 -16.80141969   0.        ]\n",
      " [ -7.20805564 -13.6502765    0.        ]\n",
      " [ -5.61726259 -12.29596087   0.        ]\n",
      " [ -7.10372193 -13.73013564   0.        ]\n",
      " [ -6.43334104 -12.32398554   0.        ]\n",
      " [ -8.23537915 -14.64145033   0.        ]\n",
      " [-11.61046754 -19.20939535   0.        ]\n",
      " [ -4.55027348 -11.61041628   0.        ]\n",
      " [ -6.89012015  -8.78314197   0.        ]\n",
      " [ -3.95201428 -12.00927461   0.        ]\n",
      " [ -8.7823267  -17.49723178   0.        ]\n",
      " [ -8.10507387 -14.54883134   0.        ]\n",
      " [ -5.87619649 -10.86744623   0.        ]\n",
      " [ -7.44722902 -15.92176925   0.        ]\n",
      " [ -6.86841374 -13.88039773   0.        ]\n",
      " [ -8.59982755 -17.88965043   0.        ]\n",
      " [ -4.70897422 -10.49699539   0.        ]\n",
      " [ -6.84267648 -11.50801209   0.        ]\n",
      " [ -6.25738204 -11.4455287    0.        ]\n",
      " [ -8.30787011 -14.26179499   0.        ]\n",
      " [ -7.70072339 -14.37551145   0.        ]\n",
      " [ -7.5678762  -13.00598581   0.        ]\n",
      " [ -6.85883038 -12.02250333   0.        ]\n",
      " [ -5.37586951 -11.73629386   0.        ]\n",
      " [ -6.71731589 -11.4876137    0.        ]\n",
      " [ -5.54875373  -9.50439445   0.        ]\n",
      " [ -6.44665327 -12.64510059   0.        ]\n",
      " [ -7.85728092 -15.09854159   0.        ]\n",
      " [-12.26586008 -21.16722515   0.        ]\n",
      " [ -6.7035641  -14.40002751   0.        ]\n",
      " [ -7.90621678 -14.25068123   0.        ]\n",
      " [ -6.48304241 -13.11421788   0.        ]\n",
      " [ -7.75037457 -12.73497145   0.        ]\n",
      " [ -7.70458251 -13.24560093   0.        ]\n",
      " [-13.16691751 -23.94722198   0.        ]\n",
      " [ -7.55666546 -11.902605     0.        ]\n",
      " [ -7.5380756  -14.68615773   0.        ]\n",
      " [ -7.36063341 -12.88834717   0.        ]\n",
      " [ -9.72399194 -18.29271949   0.        ]\n",
      " [ -8.4292872  -16.75974617   0.        ]\n",
      " [ -8.72054276 -16.83031856   0.        ]\n",
      " [ -5.29126361  -9.03455929   0.        ]\n",
      " [ -9.29909499 -19.97025942   0.        ]\n",
      " [ -7.27358972 -16.4239325    0.        ]\n",
      " [-10.74051471 -23.65663412   0.        ]\n",
      " [ -5.60760438  -8.41692345   0.        ]\n",
      " [ -6.24759694 -10.472198     0.        ]\n",
      " [ -7.61516469 -13.51276274   0.        ]\n",
      " [ -6.2452859  -10.82622129   0.        ]\n",
      " [ -6.18998304 -14.06737871   0.        ]\n",
      " [ -7.30838394 -15.76997722   0.        ]\n",
      " [ -5.60665972  -8.81680856   0.        ]\n",
      " [-10.23170259 -20.31948487   0.        ]\n",
      " [ -4.31382543 -10.24311988   0.        ]\n",
      " [ -5.81298048 -12.06633374   0.        ]\n",
      " [ -9.05300973 -16.78649357   0.        ]\n",
      " [ -6.61867352 -14.74047652   0.        ]\n",
      " [-10.02659058 -19.06079307   0.        ]\n",
      " [ -6.80180585 -14.40623993   0.        ]\n",
      " [ -7.00515134 -14.72483031   0.        ]\n",
      " [ -8.81979825 -16.72780954   0.        ]\n",
      " [ -7.38174958 -16.00399154   0.        ]\n",
      " [ -7.31896807 -14.77264244   0.        ]\n",
      " [ -7.67987914 -14.3268529    0.        ]\n",
      " [ -8.9350506  -14.2235522    0.        ]\n",
      " [ -6.04733277  -9.93591861   0.        ]\n",
      " [ -7.21917636 -14.4601408    0.        ]\n",
      " [ -7.48314667 -14.66666409   0.        ]\n",
      " [ -4.3131518  -10.63045261   0.        ]\n",
      " [-11.06547258 -21.66678793   0.        ]\n",
      " [ -7.65478976 -15.5940821    0.        ]\n",
      " [ -7.59148723 -16.6527247    0.        ]\n",
      " [ -5.07506501  -8.77845626   0.        ]\n",
      " [ -9.98969771 -16.1587584    0.        ]\n",
      " [ -9.37450962 -18.56012737   0.        ]\n",
      " [ -5.32108102  -9.51751585   0.        ]\n",
      " [ -9.64110172 -17.32726796   0.        ]\n",
      " [ -7.41553573 -15.37360235   0.        ]\n",
      " [ -8.90435594 -16.91053693   0.        ]\n",
      " [-11.16380929 -21.79068743   0.        ]\n",
      " [ -6.36066914 -12.2167342    0.        ]\n",
      " [ -4.42777762 -10.35059708   0.        ]\n",
      " [ -4.82851663  -9.38295057   0.        ]\n",
      " [ -5.41789467  -9.49534293   0.        ]\n",
      " [ -7.94884757 -12.3492915    0.        ]\n",
      " [ -8.46355223 -14.43505792   0.        ]\n",
      " [ -9.37959893 -13.60429651   0.        ]\n",
      " [ -8.03341171 -17.38494778   0.        ]\n",
      " [ -7.63877427 -13.01401479   0.        ]\n",
      " [-10.30628013 -19.73989231   0.        ]\n",
      " [ -8.17926351 -11.17798915   0.        ]\n",
      " [-12.30829065 -25.82958981   0.        ]\n",
      " [ -7.510023   -16.52093461   0.        ]\n",
      " [ -4.3467918   -9.81116792   0.        ]\n",
      " [ -7.46339556 -15.74053678   0.        ]\n",
      " [ -5.64784569 -12.70460917   0.        ]\n",
      " [ -8.5926377  -16.46311597   0.        ]\n",
      " [ -8.21464959 -15.30427454   0.        ]\n",
      " [ -8.33695209 -12.17470785   0.        ]\n",
      " [ -5.7500929   -9.15134796   0.        ]\n",
      " [ -5.01584402 -11.77521146   0.        ]\n",
      " [ -9.2209913  -16.94138706   0.        ]\n",
      " [ -6.14488437 -14.90782937   0.        ]\n",
      " [ -8.2769948  -13.58710292   0.        ]\n",
      " [ -7.29249072 -15.28231163   0.        ]\n",
      " [ -3.29449267 -10.1996388    0.        ]\n",
      " [ -8.38796883 -13.42104692   0.        ]\n",
      " [ -6.86319887 -13.66475886   0.        ]\n",
      " [ -6.22805424 -15.67233036   0.        ]\n",
      " [ -7.57621491 -16.12265112   0.        ]\n",
      " [ -9.30394498 -18.17193775   0.        ]\n",
      " [ -9.27448457 -18.02273342   0.        ]\n",
      " [ -8.51781411  -8.69951462   1.        ]\n",
      " [-14.13730902 -14.86324144   1.        ]\n",
      " [ -7.3548327  -11.88676057   1.        ]\n",
      " [ -7.53904506 -14.00548048   1.        ]\n",
      " [-13.25850843 -14.39956028   1.        ]\n",
      " [-12.80818569 -16.29113916   1.        ]\n",
      " [-12.36529438 -21.28669249   1.        ]\n",
      " [-13.90450703 -12.53466273   1.        ]\n",
      " [-14.94856745 -22.26887021   1.        ]\n",
      " [-10.86762209 -12.26341311   1.        ]\n",
      " [-14.174436   -19.53218177   1.        ]\n",
      " [-10.03291801 -12.28480278   1.        ]\n",
      " [-15.48785912 -26.28615621   1.        ]\n",
      " [-16.12963177 -23.38479692   1.        ]\n",
      " [-11.1659154   -9.03878913   1.        ]\n",
      " [-14.61907152 -17.55463002   1.        ]\n",
      " [-13.83554737 -15.20742054   1.        ]\n",
      " [-13.49629202 -21.47426596   1.        ]\n",
      " [-11.6790776  -16.65350532   1.        ]\n",
      " [-13.19359604 -19.01572517   1.        ]\n",
      " [ -8.37192215 -10.29616981   1.        ]\n",
      " [-11.38459377 -17.06948672   1.        ]\n",
      " [-13.28427685 -22.70935381   1.        ]\n",
      " [ -7.54661032 -13.61237825   1.        ]\n",
      " [-16.1663457  -22.29838066   1.        ]\n",
      " [ -7.58414213 -12.50096693   1.        ]\n",
      " [-10.36698343 -14.78070487   1.        ]\n",
      " [-11.6203226  -10.62830091   1.        ]\n",
      " [ -7.19161078 -12.4189748    1.        ]\n",
      " [-11.42691069 -16.64454336   1.        ]\n",
      " [ -7.15441545 -16.27732587   1.        ]\n",
      " [ -7.43939143  -8.71380013   1.        ]\n",
      " [-11.75816259 -10.30516109   1.        ]\n",
      " [-14.27069864 -17.59447499   1.        ]\n",
      " [ -9.74766597 -16.10840394   1.        ]\n",
      " [-11.12810721  -6.6883032    1.        ]\n",
      " [ -9.15624453 -11.26283832   1.        ]\n",
      " [ -7.87637341  -8.15505184   1.        ]\n",
      " [-15.44933701 -25.49689743   1.        ]\n",
      " [ -8.89351484 -12.59606222   1.        ]\n",
      " [ -9.5086488  -13.78695924   1.        ]\n",
      " [ -8.16764777 -11.72404289   1.        ]\n",
      " [ -8.89051528 -10.43889302   1.        ]\n",
      " [-11.2609838  -16.26181964   1.        ]\n",
      " [-14.09951814 -16.01703803   1.        ]\n",
      " [ -4.15097257 -10.25624943   1.        ]\n",
      " [ -8.99366793  -7.3965965    1.        ]\n",
      " [-10.22759175  -9.29912073   1.        ]\n",
      " [-13.67693673 -21.36703054   1.        ]\n",
      " [-13.24347049 -23.9316945    1.        ]\n",
      " [ -7.61385386 -10.85567057   1.        ]\n",
      " [ -9.98997511 -16.59530482   1.        ]\n",
      " [-12.90650685 -12.8678525    1.        ]\n",
      " [-21.2711196  -31.90455909   1.        ]\n",
      " [-15.02606151 -18.59328355   1.        ]\n",
      " [-10.02997106 -10.63980773   1.        ]\n",
      " [-10.85186951 -13.01107493   1.        ]\n",
      " [ -6.97348836  -7.83417271   1.        ]\n",
      " [-16.21644788 -22.76581336   1.        ]\n",
      " [-13.10848123 -17.56990622   1.        ]\n",
      " [ -8.99403888 -12.18037223   1.        ]\n",
      " [-16.10732987 -21.07605575   1.        ]\n",
      " [ -8.32400796 -13.24218507   1.        ]\n",
      " [-15.49873271 -21.75123812   1.        ]\n",
      " [-10.93101577 -15.79663511   1.        ]\n",
      " [ -7.18236501 -11.57096239   1.        ]\n",
      " [-11.96937143 -18.52797614   1.        ]\n",
      " [-17.42721899 -24.01891143   1.        ]\n",
      " [ -9.5457744  -16.70811608   1.        ]\n",
      " [ -5.20186034  -8.70637737   1.        ]\n",
      " [ -8.64836132  -8.32049635   1.        ]\n",
      " [ -5.76967813  -8.90657256   1.        ]\n",
      " [ -6.88895374 -13.7334343    1.        ]\n",
      " [-10.7090343  -13.64856143   1.        ]\n",
      " [ -9.20251751 -11.71762312   1.        ]\n",
      " [ -7.95931699 -10.76389605   1.        ]\n",
      " [ -7.48261398  -8.16172952   1.        ]\n",
      " [-13.55722518 -16.27668276   1.        ]\n",
      " [-11.36710715 -15.2534189    1.        ]\n",
      " [ -9.35709104 -12.89862786   1.        ]\n",
      " [-11.99421077 -17.04269838   1.        ]\n",
      " [ -9.07589985 -16.7833357    1.        ]\n",
      " [ -5.43927417  -8.48396088   1.        ]\n",
      " [-12.44514288 -15.28886929   1.        ]\n",
      " [-10.13170684 -12.07053244   1.        ]\n",
      " [ -9.66981324 -14.08986662   1.        ]\n",
      " [-11.94643473 -16.1168755    1.        ]\n",
      " [ -9.8227032  -11.26682955   1.        ]\n",
      " [ -8.6507077   -6.93164669   1.        ]\n",
      " [-10.296302   -11.98053215   1.        ]\n",
      " [ -9.50177094  -8.7479581    1.        ]\n",
      " [-15.16507598 -17.56777882   1.        ]\n",
      " [ -8.88699557  -7.44213259   1.        ]\n",
      " [ -9.90005458 -18.8244672    1.        ]\n",
      " [-10.47890913 -15.95125022   1.        ]\n",
      " [-14.46295861 -21.59412823   1.        ]\n",
      " [-11.72414006 -15.71232294   1.        ]\n",
      " [ -7.80092848 -11.14741033   1.        ]\n",
      " [ -9.95464643 -14.8828414    1.        ]\n",
      " [ -5.56151551  -8.91542969   1.        ]\n",
      " [ -8.56626949 -13.19591565   1.        ]\n",
      " [ -7.16648137 -11.87110408   1.        ]\n",
      " [-12.18965053 -20.45072687   1.        ]\n",
      " [-11.77944808 -12.96576229   1.        ]\n",
      " [ -9.38886374 -14.88974237   1.        ]\n",
      " [-11.61134598  -7.43837304   1.        ]\n",
      " [ -8.49623542  -8.3942838    1.        ]\n",
      " [ -8.27236506  -8.97259853   1.        ]\n",
      " [ -9.70465008 -15.20710713   1.        ]\n",
      " [ -9.00024158  -8.69767094   1.        ]\n",
      " [ -9.72457117 -14.31503259   1.        ]\n",
      " [-16.75640253 -25.76052626   1.        ]\n",
      " [-15.89791818 -16.05404519   1.        ]\n",
      " [ -8.26122489  -9.87582804   1.        ]\n",
      " [-15.14167579 -19.22191652   1.        ]\n",
      " [ -7.17019907  -9.74280693   1.        ]\n",
      " [-10.72266827  -8.40163184   1.        ]\n",
      " [-10.51130995 -11.62636666   1.        ]\n",
      " [-14.47940976 -23.5644241    1.        ]\n",
      " [-11.46465749 -13.73768198   1.        ]\n",
      " [-10.05347858  -9.85958482   1.        ]\n",
      " [-13.1671205  -17.09984156   1.        ]\n",
      " [ -9.33723902 -14.05693147   1.        ]\n",
      " [-11.80627219 -17.30295928   1.        ]\n",
      " [-14.23950873 -19.19944334   1.        ]\n",
      " [-10.89698861 -14.12560811   1.        ]\n",
      " [ -6.30139415 -10.12658531   1.        ]\n",
      " [-12.17275905 -15.95211902   1.        ]\n",
      " [-18.0759975  -26.73061734   1.        ]\n",
      " [-10.87211622 -12.81876242   1.        ]\n",
      " [-11.79450609 -12.90582183   1.        ]\n",
      " [ -9.04755534  -8.35014956   1.        ]\n",
      " [-12.24626952 -17.57885137   1.        ]\n",
      " [-10.32147327 -12.17125879   1.        ]\n",
      " [ -8.14880741  -8.65586877   1.        ]\n",
      " [-11.50228134 -14.99943707   1.        ]\n",
      " [ -8.93827559 -15.08709702   1.        ]\n",
      " [-11.60424841 -19.65300101   1.        ]\n",
      " [ -9.16725059  -7.86214431   1.        ]\n",
      " [ -8.52849871 -10.21211047   1.        ]\n",
      " [ -8.02326877  -9.00118868   1.        ]\n",
      " [-10.83199688 -14.48577778   1.        ]\n",
      " [-13.34232564 -16.40009828   1.        ]\n",
      " [-12.60247833 -17.72743101   1.        ]\n",
      " [-13.51725417 -21.35407138   1.        ]]\n",
      "11 (208, 3)\n",
      "10 (209, 3)\n",
      "17 (209, 3)\n"
     ]
    }
   ],
   "source": [
    "Dc = D.copy()\n",
    "print(Dc)\n",
    "# randomize and split to D1 + D2\n",
    "np.random.seed(seed=42)\n",
    "np.random.shuffle(Dc)\n",
    "split = int(Dc[:,0].size/3)\n",
    "split2 = 2*split\n",
    "D1, D2, D3 = Dc[:split,:], Dc[split:split2,:], Dc[split2:]\n",
    "\n",
    "# train on one, estimate on the other\n",
    "for T,Q in [ (np.vstack([D1,D2]),D3), (np.vstack([D2,D3]),D1), (np.vstack([D3,D1]),D2)]:\n",
    "    Cpred = QDA().fit(T[:,:2],T[:,2]).predict(Q[:,:2])\n",
    "    Ctrue = Q[:,2]\n",
    "    print ((Cpred!=Ctrue).sum(), T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unhomework\n",
    "\n",
    "- Implement LDA and compare to sklearn\n",
    "\n",
    ">1. Write code without using sklearn \n",
    ">2. Apply to [training](Class-Train.csv) and [query](Class-Query.csv) sets \n",
    ">3. Compare your results to sklearn's \n",
    "\n",
    "- Perform 10-fold cross-validation of *MyQDA* on [this](Class-Train.csv) file\n",
    "\n",
    ">1. Write code without using `sklearn` \n",
    ">2. Calculate average number of good classifications \n",
    ">3. Compare to sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8125    , 0.875     , 0.75      , 0.875     , 0.8125    ,\n",
       "       0.75      , 1.        , 1.        , 1.        , 0.93333333])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = QDA()\n",
    "cross_val_score(clf, X,C, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\t 0.8125   =   0.8125\n",
      "1 :\t 0.875   =   0.875\n",
      "2 :\t 0.75   =   0.75\n",
      "3 :\t 0.875   =   0.875\n",
      "4 :\t 0.8125   =   0.8125\n",
      "5 :\t 0.75   =   0.75\n",
      "6 :\t 1.0   =   1.0\n",
      "7 :\t 1.0   =   1.0\n",
      "8 :\t 0.9333333333333333   =   0.9333333333333333\n",
      "9 :\t 1.0   =   1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k_fold = KFold(n_splits=10, shuffle=False) \n",
    "\n",
    "for k, (train, test) in enumerate(k_fold.split(X)):\n",
    "    clf.fit(X[train],C[train])\n",
    "    Cpred = clf.predict(X[test])\n",
    "    print (k, ':\\t', (C[test]==Cpred).sum() / float(test.size),\n",
    "        '  =  ', clf.score(X[test],C[test]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
